{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "layout: single\n",
    "toc: true\n",
    "published: true \n",
    "header:\n",
    "  teaser: \\assets\\images\\ML\\feedforward_train.png\n",
    "categories:\n",
    "  - Programming\n",
    "tags:\n",
    "  - Einsum\n",
    "  - Tensors\n",
    "excerpt: \"All ironic clickbait aside, the einsum function is super useful.\"\n",
    "--- \n",
    "\n",
    "> “Tensor products [are] some sort of product. . . of tensors, I believe.” - Andrew Gelman\n",
    "\n",
    "# Motivation\n",
    "\n",
    "Suppose you want to take the derivative of a $n \\times m$ matrix $A \\in \\mathbb{R}^{n \\times m}$ with respect to a $k$ length vector $v \\in \\mathbb{R}^k$. (If you have ever implemented any neural nets from scratch, you already know this is something you might want to do).  This is actually a bit tricky however, because in normal multivariate calculus, we'd represent the derivative of a $n$-length vector with respect to another $m$-length vector as a $n \\times m$ matrix. However, because we're taking the derivative of a matrix with respect to a vector, we need to calculate $n \\cdot m \\cdot k$ separate values,\n",
    "\n",
    "The solution is to use a **tensor**, which is a higher-dimensional generalization of a matrix. In particular, a vector is a 1D tensor, since it has just one axis, and a matrix is a 2D tensor, since it has two axes. More formally, if $A \\in \\mathbb{R}^{n \\times m}, v \\in \\mathbb{R}^k$, then we write\n",
    "$$ \\frac{\\partial A}{\\partial v} \\in \\mathbb{R}^{n \\times m \\times k} $$\n",
    "Similarly, if $B$ is a $k \\times d$ matrix, i.e. $B \\in \\mathbb{R}^{k \\times d}$, then we could easily take the derivative of $A$ with respect to $B$: \n",
    "$$ \\frac{\\partial A}{\\partial B} \\in \\mathbb{R}^{n \\times m \\times k \\times d} $$\n",
    "\n",
    "Unfortunately, working with tensors can be a bit annoying. Suppose you were actually trying to calculate the derivative of $A$ with respect to $B$ in Python using the chain rule, i.e. there exists some $V \\in \\mathbb{R}^{k \\times d}$, and we know\n",
    "$$ \\frac{\\partial A}{\\partial B} = \\frac{\\partial A}{\\partial V} \\cdot \\frac{\\partial V}{\\partial B}$$\n",
    "\n",
    "Implementing this tensor product would look something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 2, 6, 2)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Required argument 'b' (pos 2) not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-42757c932ca1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mdVdB_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdVdB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdVdB_t\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mdAdB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdAdV\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: Required argument 'b' (pos 2) not found"
     ]
    }
   ],
   "source": [
    "# Initializing Tensors\n",
    "import numpy as np\n",
    "n, m, k, d = 4, 3, 2, 6\n",
    "dAdV = np.random.randn(n, m, k, d)\n",
    "dVdB = np.random.randn(k, d, k, d)\n",
    "\n",
    "# Now we will compute the tensor products\n",
    "dVdB_t = dVdB.T\n",
    "intermdiary1 = np.matmul([ ])\n",
    "intermdiary2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
